Este é um chatbot que lê seus PDFs e responde perguntas sobre eles usando inteligência artificial local. Ele usa a tecnica RAG para buscar informacoes no texto e o modelo Llama 3 pelo Ollama para gerar as respostas sem gastar dinheiro com API. Tudo funciona direto no seu computador. Para usar, comece instalando o Ollama e baixando o modelo com o comando ollama pull llama3. Depois, no terminal da pasta do projeto, crie um ambiente virtual digitando python -m venv venv e o ative rodando o comando de ativação do seu sistema, como o activate na pasta Scripts ou bin. Com o ambiente ligado, instale as dependencias usando pip install -r requirements.txt. Coloque seu arquivo PDF na pasta e rode o main.py para ler o documento, e depois o chat.py para comecar a conversar com ele.